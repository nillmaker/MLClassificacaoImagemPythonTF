{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE7KNzPPVrVV"
      },
      "source": [
        "# Classificação de imagem - Faces do Nilson vs Outros\n",
        "\n",
        "### Projeto final da DIO - Trilha da EY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN7G9GFmVrVY"
      },
      "source": [
        "Esse notebook visa realizar um treinamento para ser possível identificar a face de uma determinada pessoa (no caso eu - Nilson) em detrimento à face de qualquer outra pessoa. \n",
        "\n",
        "Foram utilizados os conhecimentos adquiridos na trilha EY Fast Track Specialist - Machine Learning da DIO em parceria com a EY. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "# Importação dos pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oSdjGwVWGshH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nlORkUyFGxWH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wqtiIPRbG4FA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GHHqtPisG3R1"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPHx8-t-VrVo"
      },
      "source": [
        "Aqui serão baixados os datasets que estão armazenados no meu Google Drive.\n",
        "\n",
        "Dentro existem as classes \"outros\" e \"nilson\" que serão utilizadas no treinamento e na classificação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpUSoFjuVrVp",
        "outputId": "f68c4e07-a46a-4a18-fedc-8c67fe3b092e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://drive.google.com/u/0/uc?id=1GOCmH4-sA3oHNP4pVtyHJ3zXzPliI23m&export=download&confirm=t&uuid=4a487169-dbf6-4ba2-81a3-7db372d2993e&at=ALAFpqw9j5keI4N25VLuX4YWZfxu:1667081119859\n",
            "250695841/250695841 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "_URL = 'https://drive.google.com/u/0/uc?id=1GOCmH4-sA3oHNP4pVtyHJ3zXzPliI23m&export=download&confirm=t&uuid=4a487169-dbf6-4ba2-81a3-7db372d2993e&at=ALAFpqw9j5keI4N25VLuX4YWZfxu:1667081119859'\n",
        "zip_dir = tf.keras.utils.get_file('dataset-classific-nilson.zip', origin=_URL, extract=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Giv0wMQzVrVw"
      },
      "source": [
        "O dataset que será baixado seguirá a seguinte estrutura de diretórios: \n",
        "\n",
        "<pre style=\"font-size: 10.0pt; font-family: Arial; line-height: 2; letter-spacing: 1.0pt;\" >\n",
        "<b>dataset-classific-nilson</b>\n",
        "|__ <b>train</b>\n",
        "    |______ <b>outros</b>\n",
        "    |______ <b>nilson</b>\n",
        "|__ <b>validation</b>\n",
        "    |______ <b>outros</b>\n",
        "    |______ <b>nilson</b>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssD23VbTZeVA",
        "outputId": "73809602-b18c-426f-daba-ced4ae6195da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets\n",
            "/root/.keras/datasets/dataset-classfic-nilson\n",
            "/root/.keras/datasets/dataset-classfic-nilson/train\n",
            "/root/.keras/datasets/dataset-classfic-nilson/train/outros\n",
            "/root/.keras/datasets/dataset-classfic-nilson/train/nilson\n",
            "/root/.keras/datasets/dataset-classfic-nilson/validation\n",
            "/root/.keras/datasets/dataset-classfic-nilson/validation/outros\n",
            "/root/.keras/datasets/dataset-classfic-nilson/validation/nilson\n"
          ]
        }
      ],
      "source": [
        "zip_dir_base = os.path.dirname(zip_dir)\n",
        "!find $zip_dir_base -type d -print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sRucI3QqVrVy"
      },
      "outputs": [],
      "source": [
        "base_dir = os.path.join(os.path.dirname(zip_dir), 'dataset-classfic-nilson')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "train_outros_dir = os.path.join(train_dir, 'outros')  # diretório com as imagens de treinamento da classe \"outros\"\n",
        "train_nilson_dir = os.path.join(train_dir, 'nilson')  # diretório com as imagens de treinamento da classe \"nilson\"\n",
        "validation_outros_dir = os.path.join(validation_dir, 'outros')  # diretório com as imagens de validação da classe \"outros\"\n",
        "validation_nilson_dir = os.path.join(validation_dir, 'nilson')  # diretório com as imagens de validação da classe \"nilson\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vc4u8e9hVrV4"
      },
      "outputs": [],
      "source": [
        "num_outros_tr = len(os.listdir(train_outros_dir))\n",
        "num_nilson_tr = len(os.listdir(train_nilson_dir))\n",
        "\n",
        "num_outros_val = len(os.listdir(validation_outros_dir))\n",
        "num_nilson_val = len(os.listdir(validation_nilson_dir))\n",
        "\n",
        "total_train = num_outros_tr + num_nilson_tr\n",
        "total_val = num_outros_val + num_nilson_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4GGzGt0VrV7",
        "outputId": "f7cfa45f-5680-48b4-e2c0-1cd47c425f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total de imagens de treinamento \"outros\": 80\n",
            "total de imagens de treinamento \"nilson\" 80\n",
            "total de imagens de validação \"outros\" 20\n",
            "total de imagens de validação \"nilson\" 20\n",
            "--\n",
            "Total de imagens de treinamento: 160\n",
            "Total de imagens de validação: 40\n"
          ]
        }
      ],
      "source": [
        "print('total de imagens de treinamento \"outros\":', num_outros_tr)\n",
        "print('total de imagens de treinamento \"nilson\"', num_nilson_tr)\n",
        "\n",
        "print('total de imagens de validação \"outros\"', num_outros_val)\n",
        "print('total de imagens de validação \"nilson\"', num_nilson_val)\n",
        "print(\"--\")\n",
        "print(\"Total de imagens de treinamento:\", total_train)\n",
        "print(\"Total de imagens de validação:\", total_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdsI_L-NVrV_"
      },
      "source": [
        "#Parâmetros do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "3NqNselLVrWA"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 10  \n",
        "IMG_SHAPE  = 300  #Tamanho das imagens em pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INn-cOn1VrWC"
      },
      "source": [
        "# Preparação dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "syDdF_LWVrWE"
      },
      "outputs": [],
      "source": [
        "train_image_generator      = ImageDataGenerator(rescale=1./255)  # Generator dos dados de treinamento\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)  # Generator dos dados de validação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Pw94ajOOVrWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f7eb2c-6d6e-4a71-8744-8345ebf9ae49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 160 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_data_gen = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
        "                                                           seed=123,\n",
        "                                                           image_size=(IMG_SHAPE,IMG_SHAPE), #(300,300)\n",
        "                                                           batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4JaPcvTza3m",
        "outputId": "d0e09510-bb5c-482a-9e7e-ccd11db1e9c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nilson', 'outros']\n"
          ]
        }
      ],
      "source": [
        "class_names = train_data_gen.class_names  #Cria uma lista com as classes que serão utilizadas para posterior classificação\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oUoKUzRVrWM",
        "outputId": "448b9a98-9bf9-4b50-bb16-afef82821a79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 40 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "val_data_gen = tf.keras.utils.image_dataset_from_directory(validation_dir,\n",
        "                                                           seed=123,\n",
        "                                                           image_size=(IMG_SHAPE,IMG_SHAPE), #(300,300)\n",
        "                                                           batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5Ej-HLGVrWZ"
      },
      "source": [
        "# Criação do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEgW4i18VrWZ"
      },
      "source": [
        "## Definição do modelo\n",
        "\n",
        "Aqui serão definidos os algoritmos do modelo.\n",
        "Serão mantidos os mesmos passados no exemplo pelo prof. Diego Bruno. \n",
        "Para a predição e classificação da imagem entre as duas classes - nilson e outros -  será utilizada `softmax`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "F15-uwLPVrWa"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI5cdkMQVrWc"
      },
      "source": [
        "### Compilação do modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "6Mg7_TXOVrWd"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YmQZ3TAVrWg"
      },
      "source": [
        "### Sumário do modelo\n",
        "\n",
        "Visualizando todas as layers da nossa rede."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vtny8hmBVrWh",
        "outputId": "fb9531af-81d2-42dc-fee6-3e5b65283b4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 298, 298, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 149, 149, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 147, 147, 128)     73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 73, 73, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 71, 71, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 35, 35, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 33, 33, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 16, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32768)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               16777728  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,149,570\n",
            "Trainable params: 17,149,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N06iqE8VVrWj"
      },
      "source": [
        "### Treinamento do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oub9RtoFVrWk"
      },
      "source": [
        "Serão utizadas 50 épocas - número interessante para obter uma boa acurácia neste experimento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSF2HqhDVrWk"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE)))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojJNteAGVrWo"
      },
      "source": [
        "### Visualização do resultado do treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6oA77ADVrWp"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Acurácia do treinamento')\n",
        "plt.plot(epochs_range, val_acc, label='Acurácia da validação')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Acurácia do treinamento e validação')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Perda no treinamento')\n",
        "plt.plot(epochs_range, val_loss, label='Perda na validação')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Perda no treinamento e validação')\n",
        "plt.savefig('./foo.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "yISpPfyrMdFW"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "BbhWUZnQMfHC"
      },
      "outputs": [],
      "source": [
        "img_array = None    #Zera as variáveis apenas para garantia de valores novos\n",
        "image = None\n",
        "resize = None\n",
        "prediction = None\n",
        "score = None\n",
        "\n",
        "image = cv2.imread('/content/sample_data/nil1.jpg')   #Carrega a imagem para predição"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "q4IBZgDXMlFD"
      },
      "outputs": [],
      "source": [
        "resize = cv2.resize(image,(300,300),interpolation = cv2.INTER_AREA)    #Redimensiona a imagem carregada conforme os padrões do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "xq-1Pn2EvlY7"
      },
      "outputs": [],
      "source": [
        "img_array = tf.keras.utils.img_to_array(resize)  #Transforma a imagem em array para ser predita\n",
        "img_array = tf.expand_dims(img_array,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-zLErwHMnNP"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(img_array)\n",
        "score = tf.nn.softmax(prediction[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYiWyrLLwly1"
      },
      "outputs": [],
      "source": [
        "if class_names[np.argmax(score)] == 'nilson':\n",
        "  print('DISPOSITIVO DESBLOQUADO - NILSON IDENTIFICADO COM ' + str(100 * np.max(score)) + ' % DE CERTEZA.' )\n",
        "else:\n",
        "  print('ERRO - O DISPOSITIVO NÃO PODE SER DESBLOQUEADO PORQUE A FACE IDENTIFICADA NÃO É A DO NILSON (' + str(100 * np.max(score)) + ' % DE CERTEZA).' )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}